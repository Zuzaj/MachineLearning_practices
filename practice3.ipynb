{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdfcb824",
   "metadata": {},
   "source": [
    "# Practice 3\n",
    "\n",
    "### Martyna Baran, Zuzanna Jarlaczńska"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e6b92",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfe0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf15aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airborne</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>wallaby</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wasp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>wolf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>worm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>wren</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
       "0      aardvark     1         0     0     1         0        0         1   \n",
       "1      antelope     1         0     0     1         0        0         0   \n",
       "2          bass     0         0     1     0         0        1         1   \n",
       "3          bear     1         0     0     1         0        0         1   \n",
       "4          boar     1         0     0     1         0        0         1   \n",
       "..          ...   ...       ...   ...   ...       ...      ...       ...   \n",
       "96      wallaby     1         0     0     1         0        0         0   \n",
       "97         wasp     1         0     1     0         1        0         0   \n",
       "98         wolf     1         0     0     1         0        0         1   \n",
       "99         worm     0         0     1     0         0        0         0   \n",
       "100        wren     0         1     1     0         1        0         0   \n",
       "\n",
       "     toothed  backbone  breathes  venomous  fins  legs  tail  domestic  \\\n",
       "0          1         1         1         0     0     4     0         0   \n",
       "1          1         1         1         0     0     4     1         0   \n",
       "2          1         1         0         0     1     0     1         0   \n",
       "3          1         1         1         0     0     4     0         0   \n",
       "4          1         1         1         0     0     4     1         0   \n",
       "..       ...       ...       ...       ...   ...   ...   ...       ...   \n",
       "96         1         1         1         0     0     2     1         0   \n",
       "97         0         0         1         1     0     6     0         0   \n",
       "98         1         1         1         0     0     4     1         0   \n",
       "99         0         0         1         0     0     0     0         0   \n",
       "100        0         1         1         0     0     2     1         0   \n",
       "\n",
       "     catsize  type  \n",
       "0          1     1  \n",
       "1          1     1  \n",
       "2          0     4  \n",
       "3          1     1  \n",
       "4          1     1  \n",
       "..       ...   ...  \n",
       "96         1     1  \n",
       "97         0     6  \n",
       "98         1     1  \n",
       "99         0     7  \n",
       "100        0     2  \n",
       "\n",
       "[101 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zoo_filename = \"zoo.data\"\n",
    "columns = ['animal_name', 'hair','feathers', 'eggs', 'milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'type']\n",
    "zooData = pd.read_csv(Zoo_filename, names=columns)\n",
    "zooData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e37c7",
   "metadata": {},
   "source": [
    "Firstly I deleted the animal_name column as i believe it is not important, because we care about the group type of the aminals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cac21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zooData = zooData.drop(['animal_name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ef1d4",
   "metadata": {},
   "source": [
    "#### a) using Holdout 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf8bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "X_zoo = zooData[zooData.columns[:-1]]\n",
    "Y_zoo = zooData['type']\n",
    "\n",
    "seed = random.randint(0, 100)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_zoo, Y_zoo,test_size=0.25, random_state=seed,stratify=Y_zoo)\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_zoo, Y_zoo)\n",
    "ypred = dummy_clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29271b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "Kappa metric:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0,  0,  0,  0,  0],\n",
       "       [ 5,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(Y_test,ypred, zero_division=0))\n",
    "print(\"Kappa metric: \", metrics.cohen_kappa_score(Y_test, ypred))\n",
    "\n",
    "metrics.confusion_matrix(Y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2947d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in the Zoo Dataset\n",
      "1    0.405941\n",
      "2    0.198020\n",
      "4    0.128713\n",
      "7    0.099010\n",
      "6    0.079208\n",
      "3    0.049505\n",
      "5    0.039604\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = zooData['type'].value_counts()\n",
    "class_ratios = class_counts / len(zooData)\n",
    "print(\"Class distribution in the Zoo Dataset\")\n",
    "print(class_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cbddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in test set\n",
      "1    0.423077\n",
      "2    0.192308\n",
      "7    0.115385\n",
      "4    0.115385\n",
      "6    0.076923\n",
      "3    0.038462\n",
      "5    0.038462\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = Y_test.value_counts()\n",
    "class_ratios = class_counts / len(Y_test)\n",
    "print(\"Class distribution in test set\")\n",
    "print(class_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8337efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution thete train set\n",
      "1    0.400000\n",
      "2    0.200000\n",
      "4    0.133333\n",
      "7    0.093333\n",
      "6    0.080000\n",
      "3    0.053333\n",
      "5    0.040000\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = Y_train.value_counts()\n",
    "class_ratios = class_counts / len(Y_train)\n",
    "print(\"Class distribution thete train set\")\n",
    "print(class_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df947209",
   "metadata": {},
   "source": [
    "The ZeroR is the procedure for classification algorithms whose output is simply the most frequently occurring classification in a set of data. As we can see in our data the most frequent class is class 1. Using Hold-out method we divide our dataset into train and test parts. What is important, we need to make sure that the distributions of the classes elements is the same (or very close) in train and test sets - and this is the responsibility of the stratify parameter of dividing procedure. Then our accuracy is very similar to the frequency of this class (as we made sure the ratios are similar in test and train sets). In our example class 1 gave accuracy of 42% as in is the number of its samples in the test set. Important thing is that we set the zero_division attribute to be equal 0 and because of that we have 0's in precision column where the n/0 division occured(I wanted to notice that because it will be the same in every exercise).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd3125",
   "metadata": {},
   "source": [
    "##### b) repeted holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc9e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, seed 0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "Iteration 2, seed 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]]\n",
      "Iteration 3, seed 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]]\n",
      "Iteration 4, seed 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "Iteration 5, seed 40:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.07      0.14      0.10        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "Iteration 6, seed 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      1.00      0.32         5\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.19        26\n",
      "   macro avg       0.03      0.14      0.05        26\n",
      "weighted avg       0.04      0.19      0.06        26\n",
      "\n",
      "[[5 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n",
      "Iteration 7, seed 60:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]]\n",
      "Iteration 8, seed 70:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "Iteration 9, seed 80:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      1.00      0.47         8\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.31        26\n",
      "   macro avg       0.04      0.14      0.07        26\n",
      "weighted avg       0.09      0.31      0.14        26\n",
      "\n",
      "[[8 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]]\n",
      "Iteration 10, seed 90:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]]\n",
      "Iteration 11, seed 100:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.07      0.17      0.10        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]]\n",
      "Iteration 12, seed 110:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 13, seed 120:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, seed 130:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [7 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]]\n",
      "Iteration 15, seed 140:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.07      0.14      0.09        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]]\n",
      "Iteration 16, seed 150:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]]\n",
      "Iteration 17, seed 160:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.07      0.17      0.10        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 18, seed 170:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]]\n",
      "Iteration 19, seed 180:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.08      0.20      0.12        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [ 3  0  0  0  0]]\n",
      "Iteration 20, seed 190:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]]\n",
      "Iteration 21, seed 200:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]]\n",
      "Iteration 22, seed 210:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n",
      "Iteration 23, seed 220:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.06      0.17      0.09        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 24, seed 230:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "Iteration 25, seed 240:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]]\n",
      "Iteration 26, seed 250:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.06      0.17      0.09        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 27, seed 260:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.07      0.14      0.09        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]]\n",
      "Iteration 28, seed 270:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 29, seed 280:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [7 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]]\n",
      "Iteration 30, seed 290:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      1.00      0.47         8\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.31        26\n",
      "   macro avg       0.05      0.17      0.08        26\n",
      "weighted avg       0.09      0.31      0.14        26\n",
      "\n",
      "[[8 0 0 0 0 0]\n",
      " [7 0 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [5 0 0 0 0 0]\n",
      " [3 0 0 0 0 0]\n",
      " [2 0 0 0 0 0]]\n",
      "Average accuracy is: 0.4000000000000002 and the standard deviation is 0.06481653671674122\n"
     ]
    }
   ],
   "source": [
    "accuracies =[]\n",
    "\n",
    "for i in range(30):\n",
    "    seed = i*10\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zoo, Y_zoo, test_size=0.25, random_state=seed)\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    y_pred = dummy_clf.predict(X_test)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(f\"Iteration {i+1}, seed {seed}:\\n{report}\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    acc= metrics.accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "\n",
    "accur = sum(accuracies)/30\n",
    "\n",
    "print(f\"Average accuracy is: {accur} and the standard deviation is {np.std(accuracies)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f934b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, seed 122:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]]\n",
      "Iteration 2, seed 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      1.00      0.70        14\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.11      0.20      0.14        26\n",
      "weighted avg       0.29      0.54      0.38        26\n",
      "\n",
      "[[14  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 2  0  0  0  0]]\n",
      "Iteration 3, seed 248:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n",
      "Iteration 4, seed 246:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]]\n",
      "Iteration 5, seed 250:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "Iteration 6, seed 153:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.10      0.20      0.13        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 7  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0  0  0]]\n",
      "Iteration 7, seed 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]]\n",
      "Iteration 8, seed 63:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "Iteration 9, seed 197:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "Iteration 10, seed 88:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 11, seed 288:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n",
      "Iteration 12, seed 196:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.07      0.17      0.10        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 13, seed 30:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      1.00      0.70        14\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.09      0.17      0.12        26\n",
      "weighted avg       0.29      0.54      0.38        26\n",
      "\n",
      "[[14  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]]\n",
      "Iteration 14, seed 20:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.06      0.17      0.09        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]]\n",
      "Iteration 15, seed 175:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]]\n",
      "Iteration 16, seed 294:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.05      0.14      0.08        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, seed 191:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]]\n",
      "Iteration 18, seed 68:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      1.00      0.47         8\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31        26\n",
      "   macro avg       0.04      0.14      0.07        26\n",
      "weighted avg       0.09      0.31      0.14        26\n",
      "\n",
      "[[8 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "Iteration 19, seed 183:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]]\n",
      "Iteration 20, seed 56:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0]]\n",
      "Iteration 21, seed 282:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      1.00      0.56        10\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        26\n",
      "   macro avg       0.06      0.17      0.09        26\n",
      "weighted avg       0.15      0.38      0.21        26\n",
      "\n",
      "[[10  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 22, seed 225:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.51         9\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35        26\n",
      "   macro avg       0.05      0.14      0.07        26\n",
      "weighted avg       0.12      0.35      0.18        26\n",
      "\n",
      "[[9 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "Iteration 23, seed 232:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]]\n",
      "Iteration 24, seed 282:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]]\n",
      "Iteration 25, seed 24:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      1.00      0.47         8\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.31        26\n",
      "   macro avg       0.04      0.14      0.07        26\n",
      "weighted avg       0.09      0.31      0.14        26\n",
      "\n",
      "[[8 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]]\n",
      "Iteration 26, seed 33:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.10      0.20      0.13        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0]\n",
      " [ 6  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0  0  0]]\n",
      "Iteration 27, seed 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      1.00      0.63        12\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.09      0.20      0.13        26\n",
      "weighted avg       0.21      0.46      0.29        26\n",
      "\n",
      "[[12  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [ 2  0  0  0  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 5  0  0  0  0]]\n",
      "Iteration 28, seed 59:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.08      0.17      0.11        26\n",
      "weighted avg       0.25      0.50      0.33        26\n",
      "\n",
      "[[13  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]]\n",
      "Iteration 29, seed 54:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.07      0.17      0.10        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0]\n",
      " [ 6  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, seed 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        11\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.42        26\n",
      "   macro avg       0.06      0.14      0.08        26\n",
      "weighted avg       0.18      0.42      0.25        26\n",
      "\n",
      "[[11  0  0  0  0  0  0]\n",
      " [ 8  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0]]\n",
      "Average accuracy is: 0.41538461538461546 and the standard deviation is 0.06691276077281995\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i in range(30):\n",
    "    seed = random.randint(0,300)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_zoo, Y_zoo, test_size=0.25)\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    y_pred = dummy_clf.predict(X_test)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(f\"Iteration {i+1}, seed {seed}:\\n{report}\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    acc= metrics.accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    \n",
    "accur = sum(accuracies)/30\n",
    "\n",
    "print(f\"Average accuracy is: {accur} and the standard deviation is {np.std(accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f695945",
   "metadata": {},
   "source": [
    "The characteristic feature of Repeted Holdout method is the fact that we don't have ensurance that every class representant will appear in test set. Because of that we can obtained (sometimes very) different results as despite having in test set more samples from for example class 2 we still classify everything as class 1. \n",
    "\n",
    "\n",
    "In every iteration and every split of dataset we still got the division in which we classify everything to the most frequent class which is the first one. We have performed this algorithm twice: \n",
    "- with the seed value eqal number of iteation multiplied by 10 \n",
    "- with random number from range (0,300) (which is almost the same as multiplying by 10).\n",
    "We did it mostly because of curiosity of how the random_seed parameter influence the results.\n",
    "\n",
    "In the first, the accuracy is in range 0.19 with seed 50 to 0.5 with seed 40 (so one after another). In both cases we have all the classes in test set. Pretty high results we also get with seeds 260 and 270. The precision always equals the accuracy - it's obvious having known that precision is the fraction of properly classified instances among all classified (our case properly classified is class 1) and the accuracy is the fraction of the class 1 instances in test set. 17th times we had all the classes in the test set.\n",
    "In the second we got higher scores, because the best one was the 0.62 and the lowest 0.23. But with higher accuracy we didn't use all the classes (class 3 was skiped). The highest score with all the classes included is 0.46. All the classes were chosen 15th times.\n",
    "\n",
    "\n",
    "Macro average is calculated as sum of scores of all the class divided by numer of class present in test set. \n",
    "\n",
    "Weigtened average is calculated as multipication of fracion of given class times the value of score for this class.\n",
    "\n",
    "As we can see most of the times macro average has lower values because it treats every value equally and the Precision, Recall and F1-score are always zeros for class different than 1. In fact, weighted average also does not have very great results. \n",
    "\n",
    "\n",
    "Summing up, we calculated the average accuracy of the sets and despite higher results in the secon algorithm we get almost the same average. In both cases we got low standard deviation which is good, because it means that "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e02975",
   "metadata": {},
   "source": [
    "Repeted holdout method gave us higher possible result than the hold-out method. We can say that it might be a sightly better method as we can obtain results with different seeds. On the other hand the average accuracy was worse. \n",
    "\n",
    "So as it was the ZeroR algorithm we can say that every other algorithm should give us better results than 42-50% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b141235",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4fe03a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Study</td>\n",
       "      <td>Run</td>\n",
       "      <td>vconst_corr</td>\n",
       "      <td>vconst_2</td>\n",
       "      <td>vconst_3</td>\n",
       "      <td>vconst_4</td>\n",
       "      <td>vconst_5</td>\n",
       "      <td>vconst_7</td>\n",
       "      <td>ah_corr</td>\n",
       "      <td>ah_bolus</td>\n",
       "      <td>...</td>\n",
       "      <td>efficiency_factor</td>\n",
       "      <td>tidal_mix_max</td>\n",
       "      <td>vertical_decay_scale</td>\n",
       "      <td>convect_corr</td>\n",
       "      <td>bckgrnd_vdc1</td>\n",
       "      <td>bckgrnd_vdc_ban</td>\n",
       "      <td>bckgrnd_vdc_eq</td>\n",
       "      <td>bckgrnd_vdc_psim</td>\n",
       "      <td>Prandtl</td>\n",
       "      <td>outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8590362064372231</td>\n",
       "      <td>0.9278245357602525</td>\n",
       "      <td>0.2528656223672442</td>\n",
       "      <td>0.298838311199668</td>\n",
       "      <td>0.1705212998954166</td>\n",
       "      <td>0.735936040913738</td>\n",
       "      <td>0.4283254278810799</td>\n",
       "      <td>0.5679469417703027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2456748547110086</td>\n",
       "      <td>0.1042258652974851</td>\n",
       "      <td>0.8690907029810155</td>\n",
       "      <td>0.9975184956319734</td>\n",
       "      <td>0.4486200774528293</td>\n",
       "      <td>0.3075217871189428</td>\n",
       "      <td>0.8583103652138057</td>\n",
       "      <td>0.7969972396308247</td>\n",
       "      <td>0.8698930381357464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6060410252371287</td>\n",
       "      <td>0.4577283627625244</td>\n",
       "      <td>0.3594484227670667</td>\n",
       "      <td>0.3069573767716065</td>\n",
       "      <td>0.8433307671777179</td>\n",
       "      <td>0.9348506611513181</td>\n",
       "      <td>0.4445724883608314</td>\n",
       "      <td>0.8280149253395697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6168699015410514</td>\n",
       "      <td>0.9757855814040846</td>\n",
       "      <td>0.9143436669954098</td>\n",
       "      <td>0.8452471419276359</td>\n",
       "      <td>0.8641518680676301</td>\n",
       "      <td>0.3467126889826937</td>\n",
       "      <td>0.3565734170881721</td>\n",
       "      <td>0.4384471887114665</td>\n",
       "      <td>0.5122561439056882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9975997770308621</td>\n",
       "      <td>0.3732384871005909</td>\n",
       "      <td>0.5173993555298593</td>\n",
       "      <td>0.5049925456690189</td>\n",
       "      <td>0.6189033359884182</td>\n",
       "      <td>0.6055708232180527</td>\n",
       "      <td>0.7462253300408419</td>\n",
       "      <td>0.1959282919790389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6793550279741694</td>\n",
       "      <td>0.8034130759821791</td>\n",
       "      <td>0.6439951609962413</td>\n",
       "      <td>0.7184411332114703</td>\n",
       "      <td>0.924775074027841</td>\n",
       "      <td>0.3153714063448004</td>\n",
       "      <td>0.250642370688729</td>\n",
       "      <td>0.2856355271897175</td>\n",
       "      <td>0.3658579636572136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7834078593063168</td>\n",
       "      <td>0.1040553139561477</td>\n",
       "      <td>0.1975326951075759</td>\n",
       "      <td>0.4218371592474998</td>\n",
       "      <td>0.7420556675966105</td>\n",
       "      <td>0.4908278824153564</td>\n",
       "      <td>0.005525436956021521</td>\n",
       "      <td>0.3921232672136588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4714626999390829</td>\n",
       "      <td>0.5978789030832963</td>\n",
       "      <td>0.7616587520758105</td>\n",
       "      <td>0.3627505607476147</td>\n",
       "      <td>0.9128190944424003</td>\n",
       "      <td>0.9779711752522013</td>\n",
       "      <td>0.8459212272518521</td>\n",
       "      <td>0.6994309323594078</td>\n",
       "      <td>0.475986734584957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3</td>\n",
       "      <td>176</td>\n",
       "      <td>0.6571360217355605</td>\n",
       "      <td>0.4893749949690472</td>\n",
       "      <td>0.1337129038823251</td>\n",
       "      <td>0.4119495612103493</td>\n",
       "      <td>0.08777968800988876</td>\n",
       "      <td>0.3562886222770127</td>\n",
       "      <td>0.4802043909090571</td>\n",
       "      <td>0.0296780063990607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2805462690367778</td>\n",
       "      <td>0.3841168819254058</td>\n",
       "      <td>0.8859482824737724</td>\n",
       "      <td>0.7684815695121264</td>\n",
       "      <td>0.4594791249928272</td>\n",
       "      <td>0.3344821448761246</td>\n",
       "      <td>0.5730015586945229</td>\n",
       "      <td>0.6101831907264165</td>\n",
       "      <td>0.7377059124759399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>0.9158937899007772</td>\n",
       "      <td>0.8427200389133456</td>\n",
       "      <td>0.5189467905347961</td>\n",
       "      <td>0.09062169845371197</td>\n",
       "      <td>0.3369811584021793</td>\n",
       "      <td>0.893576032403184</td>\n",
       "      <td>0.9787026870361945</td>\n",
       "      <td>0.6748679740315614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79810830750632</td>\n",
       "      <td>0.3535461527644657</td>\n",
       "      <td>0.04479587182868272</td>\n",
       "      <td>0.9908996256417595</td>\n",
       "      <td>0.3470274911055135</td>\n",
       "      <td>0.5124990522382885</td>\n",
       "      <td>0.8105494891810748</td>\n",
       "      <td>0.5933316812928146</td>\n",
       "      <td>0.1425646001291979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>0.4785995552678489</td>\n",
       "      <td>0.9411848060916075</td>\n",
       "      <td>0.7692448065732607</td>\n",
       "      <td>0.9507760047175301</td>\n",
       "      <td>0.1894064358228611</td>\n",
       "      <td>0.1127434391204992</td>\n",
       "      <td>0.7456450003031124</td>\n",
       "      <td>0.5270963716915705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1931025246093567</td>\n",
       "      <td>0.8295629554790341</td>\n",
       "      <td>0.101506036223792</td>\n",
       "      <td>0.5488780750505006</td>\n",
       "      <td>0.3819661899030001</td>\n",
       "      <td>0.1988109947156368</td>\n",
       "      <td>0.867108223914531</td>\n",
       "      <td>0.4616317102103494</td>\n",
       "      <td>0.6528173202170163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>0.007792555536919585</td>\n",
       "      <td>0.7792874706236439</td>\n",
       "      <td>0.8674678949755616</td>\n",
       "      <td>0.7048200657474809</td>\n",
       "      <td>0.9832821685988974</td>\n",
       "      <td>0.4203031653719437</td>\n",
       "      <td>0.7106123455515546</td>\n",
       "      <td>0.1747464587976639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7611336392919638</td>\n",
       "      <td>0.4367138491141507</td>\n",
       "      <td>0.6901315704453737</td>\n",
       "      <td>0.8251331410254352</td>\n",
       "      <td>0.9816564693245002</td>\n",
       "      <td>0.1131925868193826</td>\n",
       "      <td>0.3647987067479537</td>\n",
       "      <td>0.2014691976623403</td>\n",
       "      <td>0.5365354670159933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.6080745654943813</td>\n",
       "      <td>0.03155552789361941</td>\n",
       "      <td>0.5982638455694541</td>\n",
       "      <td>0.7947711921749741</td>\n",
       "      <td>0.1456804811527642</td>\n",
       "      <td>0.3781825262419362</td>\n",
       "      <td>0.4619484540825296</td>\n",
       "      <td>0.4252905171687922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4809384926015304</td>\n",
       "      <td>0.3078155124391843</td>\n",
       "      <td>0.2316379503838511</td>\n",
       "      <td>0.4641517308579448</td>\n",
       "      <td>0.5835583837948637</td>\n",
       "      <td>0.969365045412754</td>\n",
       "      <td>0.4643311117180727</td>\n",
       "      <td>0.7603437254567527</td>\n",
       "      <td>0.7624393986085327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Study  Run           vconst_corr             vconst_2  \\\n",
       "0    Study  Run           vconst_corr             vconst_2   \n",
       "1        1    1    0.8590362064372231   0.9278245357602525   \n",
       "2        1    2    0.6060410252371287   0.4577283627625244   \n",
       "3        1    3    0.9975997770308621   0.3732384871005909   \n",
       "4        1    4    0.7834078593063168   0.1040553139561477   \n",
       "..     ...  ...                   ...                  ...   \n",
       "536      3  176    0.6571360217355605   0.4893749949690472   \n",
       "537      3  177    0.9158937899007772   0.8427200389133456   \n",
       "538      3  178    0.4785995552678489   0.9411848060916075   \n",
       "539      3  179  0.007792555536919585   0.7792874706236439   \n",
       "540      3  180    0.6080745654943813  0.03155552789361941   \n",
       "\n",
       "               vconst_3             vconst_4             vconst_5  \\\n",
       "0              vconst_3             vconst_4             vconst_5   \n",
       "1    0.2528656223672442    0.298838311199668   0.1705212998954166   \n",
       "2    0.3594484227670667   0.3069573767716065   0.8433307671777179   \n",
       "3    0.5173993555298593   0.5049925456690189   0.6189033359884182   \n",
       "4    0.1975326951075759   0.4218371592474998   0.7420556675966105   \n",
       "..                  ...                  ...                  ...   \n",
       "536  0.1337129038823251   0.4119495612103493  0.08777968800988876   \n",
       "537  0.5189467905347961  0.09062169845371197   0.3369811584021793   \n",
       "538  0.7692448065732607   0.9507760047175301   0.1894064358228611   \n",
       "539  0.8674678949755616   0.7048200657474809   0.9832821685988974   \n",
       "540  0.5982638455694541   0.7947711921749741   0.1456804811527642   \n",
       "\n",
       "               vconst_7               ah_corr            ah_bolus  ...  \\\n",
       "0              vconst_7               ah_corr            ah_bolus  ...   \n",
       "1     0.735936040913738    0.4283254278810799  0.5679469417703027  ...   \n",
       "2    0.9348506611513181    0.4445724883608314  0.8280149253395697  ...   \n",
       "3    0.6055708232180527    0.7462253300408419  0.1959282919790389  ...   \n",
       "4    0.4908278824153564  0.005525436956021521  0.3921232672136588  ...   \n",
       "..                  ...                   ...                 ...  ...   \n",
       "536  0.3562886222770127    0.4802043909090571  0.0296780063990607  ...   \n",
       "537   0.893576032403184    0.9787026870361945  0.6748679740315614  ...   \n",
       "538  0.1127434391204992    0.7456450003031124  0.5270963716915705  ...   \n",
       "539  0.4203031653719437    0.7106123455515546  0.1747464587976639  ...   \n",
       "540  0.3781825262419362    0.4619484540825296  0.4252905171687922  ...   \n",
       "\n",
       "      efficiency_factor       tidal_mix_max  vertical_decay_scale  \\\n",
       "0     efficiency_factor       tidal_mix_max  vertical_decay_scale   \n",
       "1    0.2456748547110086  0.1042258652974851    0.8690907029810155   \n",
       "2    0.6168699015410514  0.9757855814040846    0.9143436669954098   \n",
       "3    0.6793550279741694  0.8034130759821791    0.6439951609962413   \n",
       "4    0.4714626999390829  0.5978789030832963    0.7616587520758105   \n",
       "..                  ...                 ...                   ...   \n",
       "536  0.2805462690367778  0.3841168819254058    0.8859482824737724   \n",
       "537    0.79810830750632  0.3535461527644657   0.04479587182868272   \n",
       "538  0.1931025246093567  0.8295629554790341     0.101506036223792   \n",
       "539  0.7611336392919638  0.4367138491141507    0.6901315704453737   \n",
       "540  0.4809384926015304  0.3078155124391843    0.2316379503838511   \n",
       "\n",
       "           convect_corr        bckgrnd_vdc1     bckgrnd_vdc_ban  \\\n",
       "0          convect_corr        bckgrnd_vdc1     bckgrnd_vdc_ban   \n",
       "1    0.9975184956319734  0.4486200774528293  0.3075217871189428   \n",
       "2    0.8452471419276359  0.8641518680676301  0.3467126889826937   \n",
       "3    0.7184411332114703   0.924775074027841  0.3153714063448004   \n",
       "4    0.3627505607476147  0.9128190944424003  0.9779711752522013   \n",
       "..                  ...                 ...                 ...   \n",
       "536  0.7684815695121264  0.4594791249928272  0.3344821448761246   \n",
       "537  0.9908996256417595  0.3470274911055135  0.5124990522382885   \n",
       "538  0.5488780750505006  0.3819661899030001  0.1988109947156368   \n",
       "539  0.8251331410254352  0.9816564693245002  0.1131925868193826   \n",
       "540  0.4641517308579448  0.5835583837948637   0.969365045412754   \n",
       "\n",
       "         bckgrnd_vdc_eq    bckgrnd_vdc_psim             Prandtl  outcome  \n",
       "0        bckgrnd_vdc_eq    bckgrnd_vdc_psim             Prandtl  outcome  \n",
       "1    0.8583103652138057  0.7969972396308247  0.8698930381357464        0  \n",
       "2    0.3565734170881721  0.4384471887114665  0.5122561439056882        1  \n",
       "3     0.250642370688729  0.2856355271897175  0.3658579636572136        1  \n",
       "4    0.8459212272518521  0.6994309323594078   0.475986734584957        1  \n",
       "..                  ...                 ...                 ...      ...  \n",
       "536  0.5730015586945229  0.6101831907264165  0.7377059124759399        1  \n",
       "537  0.8105494891810748  0.5933316812928146  0.1425646001291979        0  \n",
       "538   0.867108223914531  0.4616317102103494  0.6528173202170163        1  \n",
       "539  0.3647987067479537  0.2014691976623403  0.5365354670159933        1  \n",
       "540  0.4643311117180727  0.7603437254567527  0.7624393986085327        1  \n",
       "\n",
       "[541 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_filename = \"pop_failures.dat\"\n",
    "cols = ['Study','Run','vconst_corr','vconst_2','vconst_3','vconst_4','vconst_5','vconst_7','ah_corr','ah_bolus','slm_corr','efficiency_factor','tidal_mix_max','vertical_decay_scale','convect_corr','bckgrnd_vdc1','bckgrnd_vdc_ban','bckgrnd_vdc_eq','bckgrnd_vdc_psim','Prandtl','outcome']\n",
    "climateData = pd.read_csv(climate_filename, names=cols, sep='\\s+')\n",
    "climateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c4ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "climateData= climateData.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71cd95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.914815\n",
      "0    0.085185\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = climateData['outcome'].value_counts()\n",
    "class_ratios = class_counts / len(climateData)\n",
    "print(class_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d2dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation strategy\n",
      "Accuracy of the model with splits = 10, randm seed = 10 and number of neighbours 2 is:\n",
      " [0.92592593 0.85185185 0.77777778 0.81481481 0.7962963  0.90740741\n",
      " 0.90740741 0.92592593 0.85185185 0.83333333]\n",
      "Average accuracy is: 0.8592592592592592\n",
      "Accuracy of the model with splits = 10, randm seed = 10 and number of neighbours 6 is:\n",
      " [0.94444444 0.96296296 0.92592593 0.87037037 0.87037037 0.96296296\n",
      " 0.94444444 0.94444444 0.88888889 0.94444444]\n",
      "Average accuracy is: 0.9259259259259259\n",
      "Accuracy of the model with splits = 10, randm seed = 10 and number of neighbours 10 is:\n",
      " [0.94444444 0.94444444 0.92592593 0.87037037 0.85185185 0.96296296\n",
      " 0.96296296 0.94444444 0.88888889 0.92592593]\n",
      "Average accuracy is: 0.9222222222222222\n",
      "Leave One Out cross-validation strategy\n",
      "Accuracy of the model with number of neighbours 2 is: 0.8703703703703703\n",
      "Accuracy of the model with number of neighbours 6 is: 0.9666666666666667\n",
      "Accuracy of the model with number of neighbours 10 is: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "\n",
    "X = climateData[climateData.columns[2:-1]]\n",
    "Y = climateData['outcome']\n",
    "k=10\n",
    "seed = random.randint(0,10)\n",
    "minmaxSc = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxSc.fit(X)\n",
    "X_train_scaled = minmaxSc.transform(X)\n",
    "\n",
    "print('K-fold cross-validation strategy')\n",
    "for i in [2,6,10]:\n",
    "    \n",
    "    kfold = KFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    res = cross_val_score(model, X_train_scaled, Y, cv=kfold, scoring = 'accuracy')\n",
    "    print(f'Accuracy of the model with splits = {k}, random seed = {seed} and number of neighbors {i} is:\\n {res}')\n",
    "    print(f'Average accuracy is: {sum(res)/k}')\n",
    "    \n",
    "print('Leave One Out cross-validation strategy')    \n",
    "for i in [2,6,10]:\n",
    "    loocv = LeaveOneOut()\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    res = cross_val_score(model, X_train_scaled, Y, cv=loocv)\n",
    "    res = [str(int(x)) for x in res]\n",
    "    print(f'Accuracy of the model with number of neighbours {i} is: {metrics.accuracy_score(Y, res)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb4127b",
   "metadata": {},
   "source": [
    "Here we had very unbiased set: aproximately 91% of patterns were from class 1 and only 9% of class 2. As a result every model with accuracy below 91% is not good one. \n",
    "\n",
    "In the K-fold cross-validation strategy we got one with average accuracy only 85%, and the other two got around 92%. Having in mind the distribution of classes in out dataset those are rather poor results - it can mean that we simply classified all the patterns as class 1. \n",
    "\n",
    "On the other hand in LeaveOneOut we also get one result below 91%, but the other two got way better results! Especialy the third one that has 98% of accuracy - it is not perfect but in my opinion pretty high result. It was able to classify some of the class 2 patterns even if there were very small amount of them.\n",
    "\n",
    "So in that particular case with my value of seed, k_splits and neighbors the Leave One Out method obtained better results and can be consider as a better choice. \n",
    "\n",
    "(PS. I believe that changing teh random seed could improve the performance of the K-fold method, but then we will lose the randomness of choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4d9536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation strategy\n",
      "Accuracy of the model with splits = 5, random seed = 10 and number of neighbors 2 is:\n",
      " [0.90740741 0.78703704 0.83333333 0.91666667 0.85185185]\n",
      "Average accuracy is: 0.8592592592592594\n",
      "Accuracy of the model with splits = 5, random seed = 10 and number of neighbors 6 is:\n",
      " [0.9537037  0.89814815 0.90740741 0.94444444 0.90740741]\n",
      "Average accuracy is: 0.9222222222222223\n",
      "Accuracy of the model with splits = 5, random seed = 10 and number of neighbors 10 is:\n",
      " [0.94444444 0.89814815 0.88888889 0.9537037  0.90740741]\n",
      "Average accuracy is: 0.9185185185185185\n",
      "Leave One Out cross-validation strategy\n",
      "Accuracy of the model with number of neighbours 2 is: 0.8703703703703703\n",
      "Accuracy of the model with number of neighbours 6 is: 0.9666666666666667\n",
      "Accuracy of the model with number of neighbours 10 is: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "\n",
    "X = climateData[climateData.columns[2:-1]]\n",
    "Y = climateData['outcome']\n",
    "k=5\n",
    "#seed = random.randint(0,10)\n",
    "seed = 10\n",
    "minmaxSc = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxSc.fit(X)\n",
    "X_train_scaled = minmaxSc.transform(X)\n",
    "\n",
    "print('K-fold cross-validation strategy')\n",
    "for i in [2,6,10]:\n",
    "    \n",
    "    kfold = KFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    res = cross_val_score(model, X_train_scaled, Y, cv=kfold, scoring = 'accuracy')\n",
    "    print(f'Accuracy of the model with splits = {k}, random seed = {seed} and number of neighbors {i} is:\\n {res}')\n",
    "    print(f'Average accuracy is: {sum(res)/k}')\n",
    "    \n",
    "print('Leave One Out cross-validation strategy')    \n",
    "for i in [2,6,10]:\n",
    "    loocv = LeaveOneOut()\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    res = cross_val_score(model, X_train_scaled, Y, cv=loocv)\n",
    "    res = [str(int(x)) for x in res]\n",
    "    print(f'Accuracy of the model with number of neighbours {i} is: {metrics.accuracy_score(Y, res)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea44210",
   "metadata": {},
   "source": [
    "Here I also wanted to perform this algorithm with k=5 number of splits and with the same seed to see how each parameter influences the results. As we can see they are very similar as before with k=10. We conclude that in this case this parameter do not have a lot of power, but maybe changing both number of splits and seed we would be able to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e670b9a",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9e7d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = [\n",
    "    [4.6, 3.2, 1.4, 1],\n",
    "    [5.3, 3.7, 1.5, 3],\n",
    "    [5.7, 4.4, 1.5, 1],\n",
    "    [5, 3.5, 1.6, 2],\n",
    "    [5.5, 2.5,4,1],\n",
    "    [5.7, 3, 4.2, 2],\n",
    "    [5.7, 2.8, 4.1, 2],\n",
    "    [5.8, 2.7, 5.1, 1],\n",
    "    [6.3, 2.5, 5, 2],\n",
    "    [5.9, 3, 5.1, 3]\n",
    "]\n",
    "columns =['x1', 'x2', 'x3', 'class']\n",
    "rows = ['1', '2', '3', '4', '5', '6', '7', '8','9', '10']\n",
    "train = pd.DataFrame(trainData, columns=columns, index=rows)\n",
    "\n",
    "X_train = train[train.columns[:-1]]\n",
    "Y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec698082",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = [\n",
    "    [5, 3.5, 1.7, 1],\n",
    "    [4.3, 2.8, 1.5, 1],\n",
    "    [2.7, 4.5, 1.2, 3],\n",
    "    [5, 4.2, 1.3, 3],\n",
    "    [6.3, 2.5, 4.1, 1],\n",
    "    [5.2, 3, 4.5, 2],\n",
    "    [4.5, 3, 4.2, 2],\n",
    "    [5.9, 2.9, 5.2, 2],\n",
    "    [5, 2.4, 5.1, 1],\n",
    "    [4.5, 3.2, 5, 2]\n",
    "]\n",
    "    \n",
    "test = pd.DataFrame(testData, columns=columns, index=rows)\n",
    "X_test = test[test.columns[:-1]]\n",
    "Y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61212fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "minmaxSc = MinMaxScaler(feature_range=(0, 1))\n",
    "minmaxSc.fit(X_train)\n",
    "X_train_scaled = minmaxSc.transform(X_train)\n",
    "X_test_scaled = minmaxSc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c576a7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.50      0.40         4\n",
      "           2       0.25      0.25      0.25         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.30        10\n",
      "   macro avg       0.19      0.25      0.22        10\n",
      "weighted avg       0.23      0.30      0.26        10\n",
      "\n",
      "Kappa value:  -0.16666666666666674\n",
      "[[2 2 0]\n",
      " [3 1 0]\n",
      " [1 1 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.67      0.50      0.57         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.37      0.42      0.37        10\n",
      "weighted avg       0.44      0.50      0.45        10\n",
      "\n",
      "Kappa value:  0.16666666666666652\n",
      "[[3 1 0]\n",
      " [2 2 0]\n",
      " [2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for i in [2,5]:\n",
    "    knn = KNeighborsClassifier(n_neighbors = i, metric='euclidean')\n",
    "    knn.fit(X_train_scaled, Y_train)\n",
    "    ypred = knn.predict(X_test_scaled)\n",
    "    print(metrics.classification_report(Y_test, ypred, zero_division=0))\n",
    "    print(\"Kappa value: \", metrics.cohen_kappa_score(Y_test, ypred))\n",
    "    print(metrics.confusion_matrix(Y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a61893",
   "metadata": {},
   "source": [
    "From the table we can see that in both cases we didn't manage to predict the member of the third class. We had only two samples of third class so it was to little for our algorithm. Also, in both cases algorithms often precidted samples to be from class 1 than 2, despite having the same number of samples from those classes. The kappa value is very dissapointing - it means that our model performed very badly, as it compares obtained accuracy with expected accuracy which can be obtained by random classifier. But in the end, having in mind that is was very easy classification with only 10 samples I think that the accuracy of 50% in the second iteration with 5 neighbors is pretty good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
