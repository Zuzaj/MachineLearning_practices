
<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a name="readme-top"></a>
<!--
*** Thanks for checking out the Best-README-Template. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag "enhancement".
*** Don't forget to give the project a star!
*** Thanks again! Now go create something AMAZING! :D
-->
<h1 align="center"> 🤖 Machine Learning practices  🤖  </h1>

<!-- TABLE OF CONTENTS -->
<details>
  <summary> ✏️Table of Contents</summary>
  <ol>
    <li>
      <a href="#authors">Authors</a>
    </li>
    <li>
      <a href="#topic">Topic</a>
    </li>
    <li>
      <a href="#practice1">Practice 1</a>
    </li>
    <li><a href="#practice2">Practice 2</a>
    </li>
    <li><a href="#practice3">Practice 3</a></li>
    <li><a href="#practice4">Practice 4</a>
    </li>
    </ul></li>
    
  </ol>
</details>



<!-- ABOUT THE PROJECTS -->
## 	👩 Authors 👨

Our group consists of 2 people:
* Martyna Baran
* Zuzanna Jarlaczyńska



<!-- GETTING STARTED -->
## 📖 Topic

This repository gathers 4 practice projects associated with a subject Machine Learning at the Universidad Loyola. In uploaded files you can find both corresponding codes and interpretations. 

<!-- practice 1 -->
## 👾 Practice 1: Data Preparation
* Database explanation: patterns and attributes
* Descriptive statistics for each attribute: mean, standard deviation, max and min values, quantiles, skewness
* Missing values
* Class distribution
* Correlation between variables
* Data visualization
* Data transformation: binarising categorical variables, data scaling and normalization
* Handling missing values: univariate and multivariate
* PCA technique
* SMOTE technique on minority classes

<!-- practice 2 -->
## 💡 Practice 2: Clustering
* K-means and medians algorithms
* Single, centroid and complete linkage methods
* Hierarchical Clustering
* Agglomerative Clustering
* DBSCAN algorithm
* External Validation Metrics

<!-- practice 3 -->

## 🔦 Practice 3: Supervised Learning
* Repeated holdout method
* K-Nearest Neighbours algorithm
* OneR and ZeroR classifiers
* 2-fold stratified and leave-one-out partitions

 
<!-- practice 4 -->
 
 ## 🦾 Practice 4: Linear and Logistic Regression
 * Linear Regression model with the holdout method
 * Logistic Regression model
 * Odds ratio analysis
 * L1 and L2 regularisations



<p align="right">(<a href="#readme-top">back to top</a>)</p>




